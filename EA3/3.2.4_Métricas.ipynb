{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Logo_DuocUC.svg/2560px-Logo_DuocUC.svg.png' width=50%, height=20%>"
      ],
      "metadata": {
        "id": "k1ZjfT4a6RMj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMBZEpm9WJNn"
      },
      "source": [
        "# Introducción \n",
        " \n",
        "\n",
        "# Regresión Logística - Validación\n",
        "$$y = \\beta_0 + x_1\\beta_1 + ... + x_k\\beta_k$$\n",
        "\n",
        "$$p = f(y)= \\frac{1}{1+e^{-y}} = \\frac{1}{1+e^{-(\\beta_0 + x_1\\beta_1 + ... + x_k\\beta_k)}}$$\n",
        " \n",
        "\n",
        "\n",
        " # Actividades \n",
        " ESTABILIDAD DE UNA MATRIZ ELÉCTRICA\n",
        "\n",
        "La estabilidad en una matriz energética del país es de suma importancia para el progreso económico y el bienestar de sus habitantes (solo tener presente la sensación de inseguridad, malestar, etc. que se puede generar con un corte no previsto puede afectar el mercado económico y el bienestar de una población)\n",
        "\n",
        "El desafio es tratar de determinar si la red es estable (columna ```stabf```) basado en un conjunto de caracteristicas disponibles:\n",
        "\n",
        "\n",
        "1. tau[x]: reaction time of participant (real from the range [0.5,10]s). Tau1 - the value for electricity producer. \n",
        "2. p[x]: nominal power consumed(negative)/produced(positive)(real). For consumers from the range [-0.5,-2]s^-2; p1 = abs(p2 + p3 + p4) \n",
        "3. g[x]: coefficient (gamma) proportional to price elasticity (real from the range [0.05,1]s^-1). g1 - the value for electricity producer. \n",
        "4. stab: the maximal real part of the characteristic equation root (if positive - the system is linearly unstable)(real) \n",
        "5. stabf: the stability label of the system (categorical: stable/unstable) \n",
        "\n",
        "\n",
        "Estos datos fueron usados en el paper: \"Towards Concise Models of Grid Stability\"\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/Electrical+Grid+Stability+Simulated+Data+\n",
        "\n",
        "¡Empezamos! \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckOW3qqxABht"
      },
      "source": [
        "## Cargamos el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQrnvRr3cTwq"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/00471/Data_for_UCI_named.csv')\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6QnkaFe-jSV"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxQuWVOEbguT"
      },
      "source": [
        "df.stabf.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giiL2yGg-EAy"
      },
      "source": [
        "df.stabf.value_counts()/df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEVP-OCk_Ixj"
      },
      "source": [
        "## Preparamos el dataset\n",
        "\n",
        "¿Por qué hay variables que se borran?\n",
        "\n",
        "Explica la celda siguiente..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnbnviiX-PXC"
      },
      "source": [
        "X = df.drop(['stab','stabf'],axis=1)\n",
        "Y = df.stabf.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WLi0fJM-p24"
      },
      "source": [
        "## Cargamos y Ajustamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pikqb_ec-nRf"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "mo1 = LogisticRegression(solver='lbfgs')\n",
        "\n",
        "mo1.fit(X, Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjq5CHsRnZNd"
      },
      "source": [
        "Yhat = mo1.predict(X)\n",
        "Yprob = mo1.predict_proba(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaYuTPLt3IyS"
      },
      "source": [
        "Yhat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KwGPwum29DM"
      },
      "source": [
        "Yprob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gw5O-Pbgc7ex"
      },
      "source": [
        "## Evaluamos los resultados\n",
        "\n",
        "Explica que significan cada una de las métricas siguientes, en cuanto al valor que están mostrando."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu7_R22ZnWPk"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y, Yhat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwQyajjXfBk7"
      },
      "source": [
        "Explica que está indicando la matriz de confusión siguiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW4UDYPYnDFe"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(Y, Yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mttAjKuv9bz2"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "enc = LabelEncoder()\n",
        "Y1 = enc.fit_transform(Y)\n",
        "Yhat1 = enc.fit_transform(Yhat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeViTIISAJHi"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(Y1,Yhat1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yPrISWTGr6K"
      },
      "source": [
        "print(Yhat[0:10])\n",
        "print(Yhat1[0:10])\n",
        "print(Yprob[0:10,])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEKM7enwGdvG"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(Y1,Yprob[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5Jrr54qPq1S"
      },
      "source": [
        "## Será necesario escalar los datos?\n",
        "\n",
        "Esto se hace ya que las características son completamente distintas en magnitudes, unidades y rango por lo que lo mejor es escalarlos para llevarlos a un mismo nivel de magnitudes.\n",
        "\n",
        "Para realizar este procedimiento importaremos el método StandarScaler.\n",
        "\n",
        "INVESTIGA!....¿por qué es necesario ESCALAR? ¿cómo funciona el método StandardScaler? ¿y el MinMaxScaler? ¿Hay otros? ¿Cuáles?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1g32SsmiUK4"
      },
      "source": [
        "####Escalamiento (opción 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cESJEhkohXYu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "fdc83424-5cdc-477d-b2dc-61b36b11ae9f"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "Xscaled = scaler.transform(X)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d7307e770504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mXscaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxPfYtS2fk3e"
      },
      "source": [
        "¿Hubo algún cambio en la verificación de las métricas?...revisa las siguientes celdas...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEIZTIYchddd"
      },
      "source": [
        "mo1 = LogisticRegression(solver='lbfgs')\n",
        "mo1.fit(Xscaled, Y)\n",
        "Yhat = mo1.predict(Xscaled)\n",
        "\n",
        "print(classification_report(Y, Yhat))\n",
        "\n",
        "print(confusion_matrix(Y, Yhat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35EjgJ3FiPrg"
      },
      "source": [
        "####Escalamiento (opción 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdp8sMLRh0er"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scalerN = MinMaxScaler()\n",
        "scalerN.fit(X)\n",
        "XscaledN = scalerN.transform(X)\n",
        "\n",
        "mo1 = LogisticRegression(solver='lbfgs')\n",
        "mo1.fit(XscaledN, Y)\n",
        "Yhat = mo1.predict(XscaledN)\n",
        "\n",
        "print(classification_report(Y, Yhat))\n",
        "\n",
        "print(confusion_matrix(Y, Yhat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ytmUTK0fwi9"
      },
      "source": [
        "¿Hubo algún cambio en las métricas? ¿ qué indican estas?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCvdDbGccsMF"
      },
      "source": [
        "## Evitando el Overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61kUCfJQcrvx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,Y,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09f-MiJidnu6"
      },
      "source": [
        "## Re-entrenamos y evaluamos los resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD1RXhCVdoN_"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "mo1 = LogisticRegression(solver='lbfgs')\n",
        "\n",
        "mo1.fit(Xtrain, Ytrain)\n",
        "\n",
        "Yhat = mo1.predict(Xtest)\n",
        "Yprob = mo1.predict_proba(Xtest)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Ytest, Yhat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVW0j9pff4sI"
      },
      "source": [
        "Explica cada una de las métricas anteriores. ¿Qué ocurre con el modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPFS4Fod0ylm"
      },
      "source": [
        "## Sintonización del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQrtN0h0z6w"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "params = {\"max_iter\": [50,100,150,200],\n",
        "          \"solver\": ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "         }\n",
        "grid = GridSearchCV(estimator=model, param_grid=params,cv=5,scoring='accuracy')\n",
        "grid.fit(Xtrain, Ytrain,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jke7aOfU26bG"
      },
      "source": [
        "print(grid.best_score_)\n",
        "print(grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjeaHWQS29wW"
      },
      "source": [
        "pd.DataFrame(grid.cv_results_).iloc[grid.best_index_]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOm2CkGZ3GK1"
      },
      "source": [
        "Yhat = grid.predict(Xtest)\n",
        "Yprob = grid.predict_proba(Xtest)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Ytest, Yhat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy4YKVyxgDiG"
      },
      "source": [
        "## CONCLUSIONES\n",
        "\n",
        "¿Es este el mejor modelo? ¿Por qué?\n",
        "\n",
        "Reflexiona sobre el ejercicio y realiza una explicación que puedas compartir con el curso."
      ]
    }
  ]
}