{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Logo_DuocUC.svg/2560px-Logo_DuocUC.svg.png' width=50%, height=20%>"
      ],
      "metadata": {
        "id": "4uh92Ag26Cqq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta4bC4cSkIZN"
      },
      "source": [
        "# Introducción\n",
        "Clasificaremos si el usuario que visita un sitio web usa como sistema operativo Windows, Macintosh o Linux.\n",
        "\n",
        "Para eso, cargaremos un pequeño archivo CSV de 170 registros. La muestra es muy pequeña, por lo cual corremos el riesgo de underfitting u overfitting.\n",
        "\n",
        "Nuestra información de entrada son 4 características tomadas de una web que utiliza Google Analytics y son:\n",
        "\n",
        "*   Duración de la visita en Segundos\n",
        "*   Cantidad de Páginas Vistas durante la Sesión\n",
        "*   Cantidad de Acciones del usuario (click, scroll, uso de checkbox, sliders,etc)\n",
        "*   Suma del Valor de las acciones (cada acción lleva asociada una valoración de importancia)\n",
        "\n",
        "Como la salida es discreta, asignaremos los siguientes valores a las etiquetas:\n",
        "\n",
        "0 – Windows\n",
        "1 – Macintosh\n",
        "2 -Linux"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYLPaQLH2_5G"
      },
      "source": [
        "## Importar las librerías \n",
        "Antes de empezar vamos a importar las siguientes librerías: \n",
        "\n",
        "- Pandas \n",
        "- Numpy \n",
        "- Sklearn\n",
        "- Matplotlib\n",
        "- Seaborn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NfWuU8y0kIZY"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFp0PHM3kIZc"
      },
      "source": [
        "## Cargamos los datos de entrada del archivo csv\n",
        "\n",
        "En este caso subiremos subir un primer archivo en forma local (el profesor te facilitirá los archivos) ejecutando lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY_I5CDWkIZe"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "    name=fn\n",
        "dataframe = pd.read_csv(name, sep=\",\")\n",
        "dataframe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qbVjzFhkIZh"
      },
      "source": [
        "dataframe.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNw3BDqwkIZj"
      },
      "source": [
        "print(dataframe.groupby('clase').size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFtyzmWWkIZk"
      },
      "source": [
        "## Visualizamos los datos\n",
        "\n",
        "Visualizamos en formato de historial las cuatro características de entrada con nombres “duración”, “páginas”,”acciones” y “valor” podemos ver gráficamente entre qué valores se comprenden sus mínimos y máximos y en qué intervalos concentran la mayor densidad de registros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4aWLdIdPkIZm"
      },
      "source": [
        "dataframe.drop(['clase'],1).hist()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nXsK_bs4JcA"
      },
      "source": [
        "También podemos interrelacionar las entradas de a pares, para ver como se concentran linealmente las salidas de usuarios por colores: Sistema Operativo Windows en azul, Macintosh en verde y Linux en rojo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "2byumv7tkIZn"
      },
      "source": [
        "sb.pairplot(dataframe.dropna(), hue='clase',size=4,vars=[\"duracion\", \"paginas\",\"acciones\",\"valor\"],kind='reg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM2YcB27kIZp"
      },
      "source": [
        "## Creamos el modelo\n",
        "\n",
        "Cargamos las variables de las 4 columnas de entrada en X excluyendo la columna “clase” con el método drop(). En cambio agregamos la columna “clase” en la variable y. Ejecutamos X.shape para comprobar la dimensión de nuestra matriz con datos de entrada de 170 registros por 4 columnas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4ht6cghkIZr"
      },
      "source": [
        "X = np.array(dataframe.drop(['clase'],1))\n",
        "y = np.array(dataframe['clase'])\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-oZ4XbN4ozd"
      },
      "source": [
        "Y creamos nuestro modelo y hacemos que se ajuste (fit) a nuestro conjunto de entradas X y salidas ‘y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxsCcZGHkIZs"
      },
      "source": [
        "model = linear_model.LogisticRegression()\n",
        "model.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZuTnGRJ4_lV"
      },
      "source": [
        "Una vez compilado nuestro modelo, le hacemos clasificar todo nuestro conjunto de entradas X utilizando el método “predict(X)” y revisamos algunas de sus salidas y vemos que coincide con las salidas reales de nuestro archivo csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MAHOakpVkIZu"
      },
      "source": [
        "predictions = model.predict(X)\n",
        "print(predictions[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT_Hw6Yd5H7Y"
      },
      "source": [
        "Y confirmamos cuan bueno fue nuestro modelo utilizando model.score() que nos devuelve la precisión media de las predicciones, en nuestro caso del 77%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2KeUTSkkIZw"
      },
      "source": [
        "model.score(X,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr9COZKqkIZy"
      },
      "source": [
        "# Validación del Modelo\n",
        "\n",
        "Subdividimos nuestros datos de entrada en forma aleatoria (mezclados) utilizando 80% de registros para entrenamiento y 20% para validar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmOKldcwkIZz"
      },
      "source": [
        "validation_size = 0.20\n",
        "seed = 7\n",
        "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, y, test_size=validation_size, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySlQ6km15bGx"
      },
      "source": [
        "Volvemos a compilar nuestro modelo de Regresión Logística pero esta vez sólo con 80% de los datos de entrada y calculamos el nuevo scoring que ahora nos da 74%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAkwmwp4kIZ0"
      },
      "source": [
        "name='Logistic Regression'\n",
        "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "cv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
        "msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "print(msg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkdL8ess5zWT"
      },
      "source": [
        "Y ahora hacemos las predicciones -en realidad clasificación- utilizando nuestro “cross validation set”, es decir del subconjunto que habíamos apartado. En este caso vemos que los aciertos fueron del 85% pero hay que tener en cuenta que el tamaño de datos era pequeño."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-SCcPmekIZ2"
      },
      "source": [
        "predictions = model.predict(X_validation)\n",
        "print(accuracy_score(Y_validation, predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkcNVnxKkIZ7"
      },
      "source": [
        "# Clasificación de nuevos registros\n",
        "\n",
        "Como último ejercicio, vamos a inventar los datos de entrada de  navegación de un usuario ficticio que tiene estos valores:\n",
        "\n",
        "- Tiempo Duración: 10\n",
        "- Paginas visitadas: 3\n",
        "- Acciones al navegar: 5\n",
        "- Valoración: 9\n",
        "\n",
        "Lo probamos en nuestro modelo y vemos que lo clasifica como un usuario tipo 2, es decir, de Linux."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5Qyrm2WkIZ8"
      },
      "source": [
        "X_new = pd.DataFrame({'duracion': [10], 'paginas': [3], 'acciones': [5], 'valor': [9]})\n",
        "model.predict(X_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEHRaUZi6Zp0"
      },
      "source": [
        "# CONCLUSIONES\n",
        "\n",
        "Intenta variar los valores para que la clasificación resultante sea con Windows y con Mac.\n",
        "\n",
        "Luego, reflexiona sobre lo ejecutado y escribe una conclusión del ejercicio."
      ]
    }
  ]
}